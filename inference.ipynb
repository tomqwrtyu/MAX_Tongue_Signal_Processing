{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2080 Ti, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "import socketio\n",
    "import tensorflow as tf\n",
    "from threading import Lock\n",
    "from tensorflow.keras.backend import clear_session\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "CHANNEL_NUMBER = 3\n",
    "SAMPLE_TIME = 1 / 500\n",
    "WINDOW_SIZE = 100\n",
    "RECEIVE_CHANNEL = 'inference'\n",
    "EMIT_CHANNEL = 'inferenceResult'\n",
    "CLASS_NUMBER = 5\n",
    "NUM_IMF = 3\n",
    "ID_LEN = 6\n",
    "BELIEF_THRESHOLD = 0.9\n",
    "\n",
    "KEY_CLASS = {0:'undefined action', 1:'up', 2:'down', 3:'left', 4:'right', 5:'quick touch'}\n",
    "MAXCHARLEN = max([len(KEY_CLASS[key]) for key in KEY_CLASS])\n",
    "\n",
    "model_path = './model/LickingPark0222'\n",
    "server_url = 'http://localhost:3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inference():\n",
    "    def __init__(self, url, modelPath) -> None:\n",
    "        # connect to socketIO server\n",
    "        self.__sio = socketio.Client()\n",
    "        self.__sio.connect(url)\n",
    "        try:\n",
    "            assert isinstance(self.__sio, socketio.Client)\n",
    "            print(\"Connected to Socket server.\")\n",
    "        except:\n",
    "            raise Exception(\"Maybe server is not online.\")\n",
    "        \n",
    "        # load model\n",
    "        self.__model = tf.keras.models.load_model(modelPath)\n",
    "        # initialize predictor\n",
    "        self.__model.predict(np.zeros((1, WINDOW_SIZE, CHANNEL_NUMBER * NUM_IMF)), verbose = False)\n",
    "        \n",
    "        self.__lock = Lock()\n",
    "        self.__white_list = {}\n",
    "        self.__req = {'uid': None, 'data': None}\n",
    "        \n",
    "        self.__sio.on('whiteList', self.__newClient)\n",
    "        self.__sio.on('rmWhiteList', self.__clientLeave)\n",
    "        \n",
    "    def __receiveSignal(self, req): # received clientID + CHANNEL_NUMBER * WINDOW_SIZE size of data\n",
    "        self.__lock.acquire()\n",
    "        self.__req = deepcopy(req)\n",
    "        self.__lock.release()\n",
    "        \n",
    "    def  __newClient(self, info):\n",
    "        self.__white_list[info['uid']] = info['stamp']\n",
    "        # print(\"New client: \",info['uid'])\n",
    "        \n",
    "    def __clientLeave(self, uid):\n",
    "        self.__white_list.pop(uid)\n",
    "        \n",
    "    def run(self):\n",
    "        print(\"Listening requests.\")\n",
    "        self.__sio.on(RECEIVE_CHANNEL, self.__receiveSignal)\n",
    "        try:\n",
    "            while True:\n",
    "                clock = time()\n",
    "                \n",
    "                try:\n",
    "                    clientID = self.__req['uid']\n",
    "                    data = np.array(self.__req['data'].split(\",\")).astype(np.float32).reshape(WINDOW_SIZE, CHANNEL_NUMBER * NUM_IMF)\n",
    "                    ser = self.__req['serial_num']\n",
    "                    \n",
    "                    self.__req.clear()\n",
    "                    assert self.__white_list.get(clientID, False), \"Client {} not in whitelist.\".format(clientID)\n",
    "                    res = self.__model.predict(data[np.newaxis, :], verbose = False).flatten()\n",
    "                    \n",
    "                    candidateIdx = np.argmax(res) + 1 if res[np.argmax(res)] > BELIEF_THRESHOLD else 0\n",
    "                    self.__sio.emit(EMIT_CHANNEL, {'uid': clientID, 'action': KEY_CLASS[candidateIdx]})\n",
    "                    print(\"ID: {}-{: 5d}, Res: {}, Spend time: {:.3f}\".format(clientID, ser, KEY_CLASS[candidateIdx], time() - clock).ljust(MAXCHARLEN + ID_LEN + 36), end='\\r')\n",
    "                \n",
    "                except KeyboardInterrupt:\n",
    "                    break\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            self.__sio.disconnect()\n",
    "            clear_session()\n",
    "            \n",
    "        finally:\n",
    "            self.__sio.disconnect()\n",
    "            clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Socket server.\n",
      "Listening requests.\n",
      "ID: 5cac08-  503, Res: undefined action, Spend time: 0.060\r"
     ]
    }
   ],
   "source": [
    "emdCNN = inference(server_url, model_path)\n",
    "emdCNN.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
